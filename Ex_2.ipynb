{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercitazione II\n",
    "1. Implementare un'architettura MLP in PyTorch e utilizzarla per un task di classificazione sul dataset MNIST.\n",
    "2. Confrontare i risultati con il dataset Digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementazione del MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzioni di attivazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di seguito sono riportate le funzioni di attivazione per lo strato nascosto (`ReLU`) e lo strato di output (`Softmax`). \\\n",
    "La scelta della ReLU è giustificata dal fatto che è la tecnica generalmente più adottata in associazione al `He` initialization. ([Referenze](#Referenze))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "    def ReLU(self, x):\n",
    "        return torch.maximum(x, torch.tensor(0.0, device=self.device))\n",
    "\n",
    "    def ReLU_derivative(self, x):\n",
    "        return (x > 0).float()\n",
    "\n",
    "    def Softmax(self, x):\n",
    "        exp_x = torch.exp(x - torch.max(x))\n",
    "        return exp_x / torch.sum(exp_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Funzione di loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "La funzione di costo scelta è la `cross-entropy loss`, ampiamente utilizzata per classificare il dataset MNIST."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "def cross_entropy_loss(self, y_pred, y_true):\n",
    "        eps = 1e-12\n",
    "        y_pred = torch.clamp(y_pred, eps, 1. - eps)\n",
    "        return -torch.sum(y_true * torch.log(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inizializzazione Kaiming-He"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa funzione serve a inizializzare i pesi tramite il metodo `He`, la quale è più adatta per le reti che utilizzano funzioni di attivazione ReLU (Rectified Linear Unit). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo metodo chiamato anche `Kaiming`, calcola i pesi come un numero casuale con una distribuzione di probabilità gaussiana con media `0,0` e deviazione standard di $\\sqrt{\\frac{2}{n}}$, dove `n` è il numero di input al nodo.\n",
    "\n",
    "$$ W \\rightarrow \\mathcal{N}(0, \\sqrt{\\frac{2}{n}})$$\n",
    "\n",
    "Per altre funzioni di attivazione, come la `sigmoide` o la `tangente iperbolica`, potrebbero essere più appropriate strategie di inizializzazione diverse."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "def initialize_weights(self):\n",
    "        weights = [None]\n",
    "        bias = [None]\n",
    "        avg_w = [None]\n",
    "        avg_b = [None]\n",
    "\n",
    "        for i in range(1, len(self.layers_config)):\n",
    "            prev_n, curr_n = self.layers_config[i-1], self.layers_config[i]\n",
    "            w = torch.normal(0, torch.sqrt(torch.tensor(2.0 / prev_n)), # formula applicata\n",
    "                             size=(curr_n, prev_n), device=self.device)\n",
    "            b = torch.zeros((curr_n, 1), device=self.device)\n",
    "            weights.append(w)\n",
    "            bias.append(b)\n",
    "            avg_w.append(torch.zeros_like(w)) # accumulatori dei gradienti medi dei pesi e dei bias\n",
    "            avg_b.append(torch.zeros_like(b))\n",
    "        return weights, bias, avg_w, avg_b # usate durante feedforward, backpropagation e aggiornamento dei pesi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzione feedforward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nella funzione di `feedforward`, `a` contiene tutte le attivazioni dei layer, e `z` i valori lineari prima della funzione di attivazione. \\\n",
    "Dopodiché viene implementato il passaggio della moltiplicazione matrice dei pesi $\\odot$ attivazione precedente, e si applica la funzione di attivazione ReLU. Il layer finale usa Softmax, perché è un problema di classificazione multiclasse."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "def feedforward(self, x, weights, bias):\n",
    "        a = [x.reshape(-1, 1)] \n",
    "        z = [None]\n",
    "        for i in range(1, len(self.layers_config) - 1):\n",
    "            z_i = torch.mm(weights[i], a[i-1]) + bias[i]\n",
    "            z.append(z_i)\n",
    "            a.append(self.ReLU(z_i))\n",
    "        z_final = torch.mm(weights[-1], a[-1]) + bias[-1]\n",
    "        y_hat = self.Softmax(z_final)\n",
    "        a.append(y_hat)\n",
    "        z.append(z_final)\n",
    "        return a, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Nella funzione di backpropagation, `delta_error` memorizza quanto ogni neurone ha contribuito all’errore finale, e `delta_error[L]` calcola il gradiente dell’errore per l’output layer. In `avg_b[L]` e `avg_w[L]` accumulo i gradienti del bias e dei pesi per l’ultimo layer. L'ultimo ciclo percorre i layer nascosti all’indietro."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "def backprop(self, a, z, y_true, weights, avg_w, avg_b):\n",
    "        delta_error = [None] * len(a)\n",
    "        L = len(self.layers_config) - 1\n",
    "\n",
    "        # Output layer\n",
    "        delta_error[L] = (a[L] - y_true.reshape(-1, 1))\n",
    "        avg_b[L] += delta_error[L]\n",
    "        avg_w[L] += torch.mm(delta_error[L], a[L-1].T)\n",
    "\n",
    "        # Hidden layers\n",
    "        for i in range(L-1, 0, -1):\n",
    "            d_relu = self.ReLU_derivative(z[i])\n",
    "            delta_error[i] = (weights[i+1].T @ delta_error[i+1]) * d_relu\n",
    "            avg_b[i] += delta_error[i]\n",
    "            avg_w[i] += torch.mm(delta_error[i], a[i-1].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il `running_loss` tiene traccia della somma delle loss di tutti i batch per poi calcolare la media finale per epoca. Il `train_loader` fornisce batch di immagini e label.\n",
    "Ogni immagine viene passata attraverso la rete che produce `a_values` e `z_values`. Dopodiché, si calcola la loss tra l’output `a_values[-1]` e `y_onehot[b].`\\\n",
    "Si accumula la loss nel batch `(batch_loss += loss.item())` e si esegue la backpropagation per aggiornare i gradienti.  \\\n",
    "Dopo aver elaborato tutti i batch, la rete viene valutata sul dataset di test, calcolando l’accuracy."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "def train(self, train_loader, test_loader, epoch_size=10, batch_size=50):\n",
    "        for epoch in range(1, epoch_size + 1):\n",
    "            print(f\"\\nEpoch {epoch}/{epoch_size}\")\n",
    "            running_loss = 0.0  # <-- somma delle loss per epoca\n",
    "\n",
    "            for i, (images, labels) in enumerate(train_loader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                y_onehot = self.one_hot(labels)\n",
    "\n",
    "                batch_loss = 0.0\n",
    "                for b in range(images.size(0)):\n",
    "                    a_values, z_values = self.feedforward(images[b], self.weights, self.bias)\n",
    "\n",
    "                    # Calcolo della loss per il sample\n",
    "                    loss = self.cross_entropy_loss(a_values[-1], y_onehot[b].reshape(-1, 1))\n",
    "                    batch_loss += loss.item()\n",
    "\n",
    "                    # Backprop\n",
    "                    self.backprop(a_values, z_values, y_onehot[b], self.weights, self.avg_w, self.avg_b)\n",
    "\n",
    "                # Media della loss del batch\n",
    "                running_loss += batch_loss / images.size(0)\n",
    "\n",
    "                # Aggiorna pesi e bias\n",
    "                for l in range(1, len(self.weights)):\n",
    "                    self.weights[l] -= (self.eta / batch_size) * self.avg_w[l]\n",
    "                    self.bias[l]    -= (self.eta / batch_size) * self.avg_b[l]\n",
    "                    self.avg_w[l].zero_()\n",
    "                    self.avg_b[l].zero_()\n",
    "\n",
    "                if (i+1) % 200 == 0:\n",
    "                    print(f\"  Batch {i+1}/{len(train_loader)}\")\n",
    "\n",
    "        \n",
    "            acc = self.validate(test_loader)\n",
    "            avg_epoch_loss = running_loss / len(train_loader)\n",
    "            self.epoch_accuracy.append(acc)\n",
    "            self.epoch_loss.append(avg_epoch_loss)\n",
    "\n",
    "            print(f\"Validation Accuracy after epoch {epoch}: {acc:.4f}\")\n",
    "            print(f\"Average Training Loss: {avg_epoch_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcolo accuretezza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funzione `validate` serve per valutare la performance della rete, invece `compute_accuracy()` è semplicemente un alias di `validate()` per eventuali usi futuri."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "    def validate(self, loader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                for b in range(images.size(0)):\n",
    "                    a_values, _ = self.feedforward(images[b], self.weights, self.bias)\n",
    "                    y_pred = a_values[-1]\n",
    "                    if torch.argmax(y_pred) == labels[b]:\n",
    "                        correct += 1\n",
    "                    total += 1\n",
    "        return correct / total\n",
    "\n",
    "    def compute_accuracy(self, loader):\n",
    "        return self.validate(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costruttore MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ManualMLP:\n",
    "    def __init__(self, layers_config, eta=0.09, device=None):\n",
    "        self.layers_config = layers_config\n",
    "        self.eta = eta\n",
    "        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.epoch_accuracy = []\n",
    "        self.epoch_loss = []  \n",
    "\n",
    "        # Inizializza pesi e bias\n",
    "        self.weights, self.bias, self.avg_w, self.avg_b = self.initialize_weights()\n",
    "\n",
    "    # -----------------------------\n",
    "    # Funzioni di attivazione\n",
    "    # -----------------------------\n",
    "    def ReLU(self, x):\n",
    "        return torch.maximum(x, torch.tensor(0.0, device=self.device))\n",
    "\n",
    "    def ReLU_derivative(self, x):\n",
    "        return (x > 0).float()\n",
    "\n",
    "    def Softmax(self, x):\n",
    "        exp_x = torch.exp(x - torch.max(x))\n",
    "        return exp_x / torch.sum(exp_x)\n",
    "\n",
    "    def one_hot(self, labels):\n",
    "        return torch.eye(self.layers_config[-1], device=self.device)[labels]\n",
    "\n",
    "    # -----------------------------\n",
    "    # Funzione di loss\n",
    "    # -----------------------------\n",
    "    def cross_entropy_loss(self, y_pred, y_true):\n",
    "        eps = 1e-12\n",
    "        y_pred = torch.clamp(y_pred, eps, 1. - eps)\n",
    "        return -torch.sum(y_true * torch.log(y_pred))\n",
    "\n",
    "    # -----------------------------\n",
    "    # Inizializzazione pesi e bias\n",
    "    # -----------------------------\n",
    "    def initialize_weights(self):\n",
    "        weights = [None]\n",
    "        bias = [None]\n",
    "        avg_w = [None]\n",
    "        avg_b = [None]\n",
    "\n",
    "        for i in range(1, len(self.layers_config)):\n",
    "            prev_n, curr_n = self.layers_config[i-1], self.layers_config[i]\n",
    "            w = torch.normal(0, torch.sqrt(torch.tensor(2.0 / prev_n)),\n",
    "                             size=(curr_n, prev_n), device=self.device)\n",
    "            b = torch.zeros((curr_n, 1), device=self.device)\n",
    "            weights.append(w)\n",
    "            bias.append(b)\n",
    "            avg_w.append(torch.zeros_like(w))\n",
    "            avg_b.append(torch.zeros_like(b))\n",
    "        return weights, bias, avg_w, avg_b\n",
    "\n",
    "    # -----------------------------\n",
    "    # Feedforward\n",
    "    # -----------------------------\n",
    "    def feedforward(self, x, weights, bias):\n",
    "        a = [x.reshape(-1, 1)]\n",
    "        z = [None]\n",
    "        for i in range(1, len(self.layers_config) - 1):\n",
    "            z_i = torch.mm(weights[i], a[i-1]) + bias[i]\n",
    "            z.append(z_i)\n",
    "            a.append(self.ReLU(z_i))\n",
    "        z_final = torch.mm(weights[-1], a[-1]) + bias[-1]\n",
    "        y_hat = self.Softmax(z_final)\n",
    "        a.append(y_hat)\n",
    "        z.append(z_final)\n",
    "        return a, z\n",
    "\n",
    "    # -----------------------------\n",
    "    # Backpropagation\n",
    "    # -----------------------------\n",
    "    def backprop(self, a, z, y_true, weights, avg_w, avg_b):\n",
    "        delta_error = [None] * len(a)\n",
    "        L = len(self.layers_config) - 1\n",
    "\n",
    "        # Output layer\n",
    "        delta_error[L] = (a[L] - y_true.reshape(-1, 1))\n",
    "        avg_b[L] += delta_error[L]\n",
    "        avg_w[L] += torch.mm(delta_error[L], a[L-1].T)\n",
    "\n",
    "        # Hidden layers\n",
    "        for i in range(L-1, 0, -1):\n",
    "            d_relu = self.ReLU_derivative(z[i])\n",
    "            delta_error[i] = (weights[i+1].T @ delta_error[i+1]) * d_relu\n",
    "            avg_b[i] += delta_error[i]\n",
    "            avg_w[i] += torch.mm(delta_error[i], a[i-1].T)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Training Loop\n",
    "    # -----------------------------\n",
    "    def train(self, train_loader, test_loader, epoch_size=10, batch_size=50):\n",
    "        for epoch in range(1, epoch_size + 1):\n",
    "            print(f\"\\nEpoch {epoch}/{epoch_size}\")\n",
    "            running_loss = 0.0  # <-- somma delle loss per epoca\n",
    "\n",
    "            for i, (images, labels) in enumerate(train_loader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                y_onehot = self.one_hot(labels)\n",
    "\n",
    "                batch_loss = 0.0\n",
    "                for b in range(images.size(0)):\n",
    "                    a_values, z_values = self.feedforward(images[b], self.weights, self.bias)\n",
    "\n",
    "                    # Calcolo della loss per il sample\n",
    "                    loss = self.cross_entropy_loss(a_values[-1], y_onehot[b].reshape(-1, 1))\n",
    "                    batch_loss += loss.item()\n",
    "\n",
    "                    # Backprop\n",
    "                    self.backprop(a_values, z_values, y_onehot[b], self.weights, self.avg_w, self.avg_b)\n",
    "\n",
    "                # Media della loss del batch\n",
    "                running_loss += batch_loss / images.size(0)\n",
    "\n",
    "                # Aggiorna pesi e bias\n",
    "                for l in range(1, len(self.weights)):\n",
    "                    self.weights[l] -= (self.eta / batch_size) * self.avg_w[l]\n",
    "                    self.bias[l]    -= (self.eta / batch_size) * self.avg_b[l]\n",
    "                    self.avg_w[l].zero_()\n",
    "                    self.avg_b[l].zero_()\n",
    "\n",
    "                if (i+1) % 200 == 0:\n",
    "                    print(f\"  Batch {i+1}/{len(train_loader)}\")\n",
    "\n",
    "            # -------------------------\n",
    "            # Validazione e logging\n",
    "            # -------------------------\n",
    "            acc = self.validate(test_loader)\n",
    "            avg_epoch_loss = running_loss / len(train_loader)\n",
    "            self.epoch_accuracy.append(acc)\n",
    "            self.epoch_loss.append(avg_epoch_loss)\n",
    "\n",
    "            print(f\"Validation Accuracy after epoch {epoch}: {acc:.4f}\")\n",
    "            print(f\"Average Training Loss: {avg_epoch_loss:.6f}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Validazione e accuratezza\n",
    "    # -----------------------------\n",
    "    def validate(self, loader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                for b in range(images.size(0)):\n",
    "                    a_values, _ = self.feedforward(images[b], self.weights, self.bias)\n",
    "                    y_pred = a_values[-1]\n",
    "                    if torch.argmax(y_pred) == labels[b]:\n",
    "                        correct += 1\n",
    "                    total += 1\n",
    "        return correct / total\n",
    "\n",
    "    def compute_accuracy(self, loader):\n",
    "        return self.validate(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisi del dataset `MNIST`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di seguito ho riportato l'architettura di questa rete (ho modificato un'immagine pronta) dove sostanzialmente gli iperparametri scelti sono:\n",
    "- `input layer`: 784 neuroni\n",
    "- `hidden layer`: 512 neuroni\n",
    "- `output layer`: 10 neuroni\n",
    "- `batch size`: 50\n",
    "- `learning rate`: 0.09\n",
    "- `activation function`: ReLU\n",
    "- `activation in output layer`: Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![architettura_rete](https://i.ibb.co/hRvc8dGL/arch-rete-drawio.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "  Batch 200/1200\n",
      "  Batch 400/1200\n",
      "  Batch 600/1200\n",
      "  Batch 800/1200\n",
      "  Batch 1000/1200\n",
      "  Batch 1200/1200\n",
      "Validation Accuracy after epoch 1: 0.9433\n",
      "Average Training Loss: 0.333508\n",
      "\n",
      "Epoch 2/10\n",
      "  Batch 200/1200\n",
      "  Batch 400/1200\n",
      "  Batch 600/1200\n",
      "  Batch 800/1200\n",
      "  Batch 1000/1200\n",
      "  Batch 1200/1200\n",
      "Validation Accuracy after epoch 2: 0.9592\n",
      "Average Training Loss: 0.171229\n",
      "\n",
      "Epoch 3/10\n",
      "  Batch 200/1200\n",
      "  Batch 400/1200\n",
      "  Batch 600/1200\n",
      "  Batch 800/1200\n",
      "  Batch 1000/1200\n",
      "  Batch 1200/1200\n",
      "Validation Accuracy after epoch 3: 0.9668\n",
      "Average Training Loss: 0.124398\n",
      "\n",
      "Epoch 4/10\n",
      "  Batch 200/1200\n",
      "  Batch 400/1200\n",
      "  Batch 600/1200\n",
      "  Batch 800/1200\n",
      "  Batch 1000/1200\n",
      "  Batch 1200/1200\n",
      "Validation Accuracy after epoch 4: 0.9727\n",
      "Average Training Loss: 0.097587\n",
      "\n",
      "Epoch 5/10\n",
      "  Batch 200/1200\n",
      "  Batch 400/1200\n",
      "  Batch 600/1200\n",
      "  Batch 800/1200\n",
      "  Batch 1000/1200\n",
      "  Batch 1200/1200\n",
      "Validation Accuracy after epoch 5: 0.9749\n",
      "Average Training Loss: 0.079731\n",
      "\n",
      "Epoch 6/10\n",
      "  Batch 200/1200\n",
      "  Batch 400/1200\n",
      "  Batch 600/1200\n",
      "  Batch 800/1200\n",
      "  Batch 1000/1200\n",
      "  Batch 1200/1200\n",
      "Validation Accuracy after epoch 6: 0.9760\n",
      "Average Training Loss: 0.067372\n",
      "\n",
      "Epoch 7/10\n",
      "  Batch 200/1200\n",
      "  Batch 400/1200\n",
      "  Batch 600/1200\n",
      "  Batch 800/1200\n",
      "  Batch 1000/1200\n",
      "  Batch 1200/1200\n",
      "Validation Accuracy after epoch 7: 0.9774\n",
      "Average Training Loss: 0.058122\n",
      "\n",
      "Epoch 8/10\n",
      "  Batch 200/1200\n",
      "  Batch 400/1200\n",
      "  Batch 600/1200\n",
      "  Batch 800/1200\n",
      "  Batch 1000/1200\n",
      "  Batch 1200/1200\n",
      "Validation Accuracy after epoch 8: 0.9793\n",
      "Average Training Loss: 0.050129\n",
      "\n",
      "Epoch 9/10\n",
      "  Batch 200/1200\n",
      "  Batch 400/1200\n",
      "  Batch 600/1200\n",
      "  Batch 800/1200\n",
      "  Batch 1000/1200\n",
      "  Batch 1200/1200\n",
      "Validation Accuracy after epoch 9: 0.9803\n",
      "Average Training Loss: 0.043847\n",
      "\n",
      "Epoch 10/10\n",
      "  Batch 200/1200\n",
      "  Batch 400/1200\n",
      "  Batch 600/1200\n",
      "  Batch 800/1200\n",
      "  Batch 1000/1200\n",
      "  Batch 1200/1200\n",
      "Validation Accuracy after epoch 10: 0.9800\n",
      "Average Training Loss: 0.038294\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Normalizzazione e flatten\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.view(-1))\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "test_data  = datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=50, shuffle=True)\n",
    "test_loader  = DataLoader(test_data, batch_size=50)\n",
    "\n",
    "mlp = ManualMLP(layers_config=[784, 512, 10], eta=0.09)\n",
    "mlp.train(train_loader, test_loader, epoch_size=10, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si osserva che già a partire dalla 4 epoca la rete raggiunge un'accuracy del `97,27%`, per poi raggiungere il `98%` nell'ultima epoca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grafico Loss & Accuracy\n",
    "plt.plot(mlp.epoch_loss, label=\"Training Loss\")\n",
    "plt.plot(mlp.epoch_accuracy, label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo grafico mostra come la loss sul training set diminuisce a partire dalle epoche iniziali. \\\n",
    "L'accuracy invece, aumenta gradualmente, pur mantenendosi valori già elevati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisi del dataset `Digits`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/30\n",
      "Validation Accuracy after epoch 1: 0.8722\n",
      "Average Training Loss: 1.660624\n",
      "\n",
      "Epoch 2/30\n",
      "Validation Accuracy after epoch 2: 0.8944\n",
      "Average Training Loss: 0.870788\n",
      "\n",
      "Epoch 3/30\n",
      "Validation Accuracy after epoch 3: 0.9139\n",
      "Average Training Loss: 0.555015\n",
      "\n",
      "Epoch 4/30\n",
      "Validation Accuracy after epoch 4: 0.9222\n",
      "Average Training Loss: 0.420979\n",
      "\n",
      "Epoch 5/30\n",
      "Validation Accuracy after epoch 5: 0.9306\n",
      "Average Training Loss: 0.343969\n",
      "\n",
      "Epoch 6/30\n",
      "Validation Accuracy after epoch 6: 0.9278\n",
      "Average Training Loss: 0.293402\n",
      "\n",
      "Epoch 7/30\n",
      "Validation Accuracy after epoch 7: 0.9361\n",
      "Average Training Loss: 0.259883\n",
      "\n",
      "Epoch 8/30\n",
      "Validation Accuracy after epoch 8: 0.9472\n",
      "Average Training Loss: 0.235057\n",
      "\n",
      "Epoch 9/30\n",
      "Validation Accuracy after epoch 9: 0.9556\n",
      "Average Training Loss: 0.214820\n",
      "\n",
      "Epoch 10/30\n",
      "Validation Accuracy after epoch 10: 0.9556\n",
      "Average Training Loss: 0.199094\n",
      "\n",
      "Epoch 11/30\n",
      "Validation Accuracy after epoch 11: 0.9583\n",
      "Average Training Loss: 0.186504\n",
      "\n",
      "Epoch 12/30\n",
      "Validation Accuracy after epoch 12: 0.9639\n",
      "Average Training Loss: 0.176891\n",
      "\n",
      "Epoch 13/30\n",
      "Validation Accuracy after epoch 13: 0.9500\n",
      "Average Training Loss: 0.165066\n",
      "\n",
      "Epoch 14/30\n",
      "Validation Accuracy after epoch 14: 0.9500\n",
      "Average Training Loss: 0.156722\n",
      "\n",
      "Epoch 15/30\n",
      "Validation Accuracy after epoch 15: 0.9667\n",
      "Average Training Loss: 0.151012\n",
      "\n",
      "Epoch 16/30\n",
      "Validation Accuracy after epoch 16: 0.9639\n",
      "Average Training Loss: 0.143811\n",
      "\n",
      "Epoch 17/30\n",
      "Validation Accuracy after epoch 17: 0.9639\n",
      "Average Training Loss: 0.137957\n",
      "\n",
      "Epoch 18/30\n",
      "Validation Accuracy after epoch 18: 0.9639\n",
      "Average Training Loss: 0.133041\n",
      "\n",
      "Epoch 19/30\n",
      "Validation Accuracy after epoch 19: 0.9667\n",
      "Average Training Loss: 0.127137\n",
      "\n",
      "Epoch 20/30\n",
      "Validation Accuracy after epoch 20: 0.9722\n",
      "Average Training Loss: 0.122856\n",
      "\n",
      "Epoch 21/30\n",
      "Validation Accuracy after epoch 21: 0.9639\n",
      "Average Training Loss: 0.117291\n",
      "\n",
      "Epoch 22/30\n",
      "Validation Accuracy after epoch 22: 0.9722\n",
      "Average Training Loss: 0.115718\n",
      "\n",
      "Epoch 23/30\n",
      "Validation Accuracy after epoch 23: 0.9722\n",
      "Average Training Loss: 0.111729\n",
      "\n",
      "Epoch 24/30\n",
      "Validation Accuracy after epoch 24: 0.9611\n",
      "Average Training Loss: 0.108578\n",
      "\n",
      "Epoch 25/30\n",
      "Validation Accuracy after epoch 25: 0.9667\n",
      "Average Training Loss: 0.104329\n",
      "\n",
      "Epoch 26/30\n",
      "Validation Accuracy after epoch 26: 0.9667\n",
      "Average Training Loss: 0.100366\n",
      "\n",
      "Epoch 27/30\n",
      "Validation Accuracy after epoch 27: 0.9750\n",
      "Average Training Loss: 0.096965\n",
      "\n",
      "Epoch 28/30\n",
      "Validation Accuracy after epoch 28: 0.9667\n",
      "Average Training Loss: 0.097157\n",
      "\n",
      "Epoch 29/30\n",
      "Validation Accuracy after epoch 29: 0.9667\n",
      "Average Training Loss: 0.092591\n",
      "\n",
      "Epoch 30/30\n",
      "Validation Accuracy after epoch 30: 0.9722\n",
      "Average Training Loss: 0.091404\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = load_digits()\n",
    "X = digits.data / 16.0  # normalizzazione [0,1]\n",
    "y = digits.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test  = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test  = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=20, shuffle=True)\n",
    "test_loader  = DataLoader(TensorDataset(X_test, y_test), batch_size=20)\n",
    "\n",
    "mlp = ManualMLP(layers_config=[64, 128, 10], eta=0.04)\n",
    "mlp.train(train_loader, test_loader, epoch_size=30, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per classificare il datasets di digits `sklearn`, è stata raggiunta un'accuracy del 97.22% dopo 20 epoche, con $\\eta$ = 0,04 e `batch_size` = 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referenze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://sausheong.github.io/posts/building-neural-networks-with-tensorflow-keras-pytorch-mxnet/\n",
    "\n",
    "- https://medium.com/@renjiniag/understanding-multilayer-perceptrons-through-mnist-digit-classification-54463c74c35eb\n",
    "\n",
    "- https://github.com/nipunmanral/MLP-Training-For-MNIST-Classification/blob/master/Different%20Configurations%20Report.pdf\n",
    "\n",
    "- https://medium.com/@piyushkashyap045/mastering-weight-initialization-in-neural-networks-a-beginners-guide-6066403140e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementazione di Batch-Normalization:\n",
    "- https://medium.com/thedeephub/batch-normalization-for-training-neural-networks-328112bda3ae (contiene cenni teorici + applicazione)\n",
    "- https://datahacker.rs/017-pytorch-how-to-apply-batch-normalization-in-pytorch/\n",
    "- https://colab.research.google.com/github/mancinimassimiliano/DeepLearningLab/blob/master/Lab3/batch_normalization.ipynb (file JupyterNotebook)\n",
    "- https://how.dev/answers/batch-normalization-implementation-in-pytorch (esempio di codice + spiegazione)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementazione di Drop-out:\n",
    "- https://d2l.ai/chapter_multilayer-perceptrons/dropout.html (esempio)\n",
    "- https://stackoverflow.com/questions/54109617/implementing-dropout-from-scratch (esempio di Inverted-dropout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (dlenv)",
   "language": "python",
   "name": "dlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
